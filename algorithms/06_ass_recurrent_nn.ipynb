{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Network Tour of Data Science\n",
    "### &nbsp; &nbsp; &nbsp; Xavier Bresson, Winter 2016/17\n",
    "## Assignment 3 : Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data: hello world! is a very simple program in most programming languages often used to illustrate the basic syntax of a programming language\n",
      "\n",
      "Single characters: ['g', 'n', 'e', '!', 'p', 'o', 'c', 'h', 'y', 'r', 'v', 'l', ' ', 'f', 'w', 'i', 't', 'd', 'm', 'a', 'b', 'x', 'u', 's']\n",
      "\n",
      "Text data has 135 characters, 24 unique.\n",
      "\n",
      "Mapping characters to numbers: {'o': 5, 'g': 0, ' ': 12, 'n': 1, 'w': 14, 'e': 2, 'i': 15, 't': 16, 'v': 10, 'u': 22, '!': 3, 'd': 17, 'p': 4, 'a': 19, 'b': 20, 'x': 21, 'c': 6, 'h': 7, 'm': 18, 'r': 9, 'l': 11, 'f': 13, 's': 23, 'y': 8}\n",
      "\n",
      "Mapping numbers to characters: {0: 'g', 1: 'n', 2: 'e', 3: '!', 4: 'p', 5: 'o', 6: 'c', 7: 'h', 8: 'y', 9: 'r', 10: 'v', 11: 'l', 12: ' ', 13: 'f', 14: 'w', 15: 'i', 16: 't', 17: 'd', 18: 'm', 19: 'a', 20: 'b', 21: 'x', 22: 'u', 23: 's'}\n"
     ]
    }
   ],
   "source": [
    "# Load text data\n",
    "data = open(os.path.join('datasets', 'text_ass_6.txt'), 'r').read() # must be simple plain text file\n",
    "print('Text data:',data)\n",
    "chars = list(set(data))\n",
    "print('\\nSingle characters:',chars)\n",
    "data_len, vocab_size = len(data), len(chars)\n",
    "print('\\nText data has %d characters, %d unique.' % (data_len, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "print('\\nMapping characters to numbers:',char_to_ix)\n",
    "print('\\nMapping numbers to characters:',ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal \n",
    "The goal is to define with TensorFlow a vanilla recurrent neural network (RNN) model:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_t &= \\textrm{tanh}(W_h h_{t-1} + W_x x_t + b_h)\\\\\n",
    "y_t &= W_y y_t + b_y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "to predict a sequence of characters. $x_t \\in \\mathbb{R}^D$ is the input character of the RNN in a dictionary of size $D$. $y_t \\in \\mathbb{R}^D$ is the predicted character (through a distribution function) by the RNN system. $h_t \\in \\mathbb{R}^H$ is the memory of the RNN, called hidden state at time $t$. Its dimensionality is arbitrarly chosen to $H$. The variables of the system are $W_h \\in \\mathbb{R}^{H\\times H}$, $W_x \\in \\mathbb{R}^{H\\times D}$, $W_h \\in \\mathbb{R}^{D\\times H}$, $b_h \\in \\mathbb{R}^D$, and $b_y \\in \\mathbb{R}^D$. <br>\n",
    "\n",
    "The number of time steps of the RNN is $T$, that is we will learn a sequence of data of length $T$: $x_t$ for $t=0,...,T-1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len= 135  batch_size= 3  batch_len= 45  T= 5  epoch_size= 8  D= 24\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters of RNN\n",
    "batch_size = 3                                  # batch size\n",
    "batch_len = data_len // batch_size              # batch length\n",
    "T = 5                                           # temporal length\n",
    "epoch_size = (batch_len - 1) // T               # nb of iterations to get one epoch\n",
    "D = vocab_size                                  # data dimension = nb of unique characters\n",
    "H = 5*D                                         # size of hidden state, the memory layer\n",
    "\n",
    "print('data_len=',data_len,' batch_size=',batch_size,' batch_len=',\n",
    "      batch_len,' T=',T,' epoch_size=',epoch_size,' D=',D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 \n",
    "Initialize input variables of the computational graph:<br>\n",
    "(1) Xin of size *batch_size x T x D* and type *tf.float32*. Each input character is encoded on a vector of size D.<br>\n",
    "(2) Ytarget of size *batch_size x T* and type *tf.int64*. Each target character is encoded by a value in {0,...,D-1}.<br>\n",
    "(3) hin of size *batch_size x H* and type *tf.float32*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input variables of computational graph (CG)\n",
    "xin = tf.placeholder(tf.float32,[batch_size,T,D]);\n",
    "Ytarget = tf.placeholder(tf.int64,[batch_size,T]);\n",
    "hin = tf.placeholder(tf.float32,[batch_size,H]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Define the variables of the computational graph:<br>\n",
    "(1) $W_x$ is a random variable of shape *D x H* with normal distribution of variance $\\frac{6}{D+H}$<br>\n",
    "(2) $W_h$ is an identity matrix multiplies by constant $0.01$<br>\n",
    "(3) $W_y$ is a random variable of shape *H x D* with normal distribution of variance $\\frac{6}{D+H}$<br>\n",
    "(4) $b_h$, $b_y$ are zero vectors of size *H*, and *D*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model variables\n",
    "Wx = tf.Variable(tf.random_normal([D,H], mean=0.0, stddev=tf.sqrt(6/(D+H)), dtype=tf.float32, seed=None, name=None)) \n",
    "Wh = tf.Variable(initial_value=0.01*np.identity(H),dtype=tf.float32)\n",
    "Wy = tf.Variable(tf.random_normal([H,D], mean=0.0, stddev=tf.sqrt(6/(D+H)), dtype=tf.float32, seed=None, name=None)) \n",
    "bh = tf.Variable(tf.zeros(H))\n",
    "by = tf.Variable(tf.zeros(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "Implement the recursive formula:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_t &= \\textrm{tanh}(W_h h_{t-1} + W_x x_t + b_h)\\\\\n",
    "y_t &= W_y h_t + b_y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with $h_{t=0}=hin$.<br>\n",
    "\n",
    "Hints: <br> \n",
    "(1) You may use functions *tf.split()*, *enumerate()*, *tf.squeeze()*, *tf.matmul()*, *tf.tanh()*, *tf.transpose()*, *append()*, *pack()*.<br>\n",
    "(2) You may use a matrix Y of shape *batch_size x T x D*. We recall that Ytarget should have the shape *batch_size x T*.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y= (3, 5, 24)\n",
      "Ytarget= (3, 5)\n"
     ]
    }
   ],
   "source": [
    "# Vanilla RNN implementation\n",
    "# Here we create the graph for training where we directly input at each timestep the known inputs.\n",
    "Y = []\n",
    "ht = hin\n",
    "\n",
    "Xt = tf.split(1,T,xin)\n",
    "\n",
    "for i,xt in enumerate(Xt):\n",
    "    xt = tf.squeeze(xt)\n",
    "    ht = tf.tanh(tf.matmul(ht,Wh)+tf.matmul(xt,Wx)+bh)\n",
    "    yt = tf.matmul(ht,Wy)+by\n",
    "    Y.append(yt)\n",
    "\n",
    "Y=tf.pack(Y,axis=1)\n",
    "\n",
    "print('Y=',Y.get_shape())\n",
    "print('Ytarget=',Ytarget.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "Perplexity loss is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perplexity\n",
    "logits = tf.reshape(Y,[batch_size*T,D])\n",
    "weights = tf.ones([batch_size*T])\n",
    "cross_entropy_perplexity = tf.nn.seq2seq.sequence_loss_by_example([logits],[Ytarget],[weights])\n",
    "cross_entropy_perplexity = tf.reduce_sum(cross_entropy_perplexity) / batch_size\n",
    "loss = cross_entropy_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "Implement the optimization of the loss function.\n",
    "\n",
    "Hint: You may use function *tf.train.GradientDescentOptimizer()*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimization\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "Implement the prediction scheme: from an input character e.g. \"h\" then the RNN should predict \"ello\". <br>\n",
    "\n",
    "Hints: <br> \n",
    "(1) You should use the learned RNN.<br>\n",
    "(2) You may use functions *tf.one_hot()*, *tf.nn.softmax()*, *tf.argmax()*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_pred = tf.placeholder(tf.int64) # input seed\n",
    "Ypred = []\n",
    "ht = tf.zeros([1,H]) \n",
    "\n",
    "xt = tf.one_hot(idx_pred,D,on_value=1.0,off_value=0.0,dtype=tf.float32)\n",
    "\n",
    "for i in range (T):\n",
    "\n",
    "    ht = tf.tanh(tf.matmul(ht,Wh)+ tf.matmul(xt,Wx) + bh)\n",
    "    yt_test = tf.matmul(ht,Wy) + by\n",
    "\n",
    "    idx_yt = tf.argmax(yt_test,1)\n",
    "\n",
    "    xt = tf.one_hot(idx_yt,D,1.0,0.0,axis=None,dtype=tf.float32)\n",
    "    Ypred.append(idx_yt)\n",
    "    \n",
    "Ypred = tf.convert_to_tensor(Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train set shape (135,)\n",
      "pre-processed train set shape (3, 45)\n"
     ]
    }
   ],
   "source": [
    "# Prepare train data matrix of size \"batch_size x batch_len\"\n",
    "data_ix = [char_to_ix[ch] for ch in data[:data_len]]\n",
    "train_data = np.array(data_ix)\n",
    "print('original train set shape',train_data.shape)\n",
    "train_data = np.reshape(train_data[:batch_size*batch_len], [batch_size,batch_len])\n",
    "print('pre-processed train set shape',train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following function tansforms an integer value d between {0,...,D-1} into an one hot vector, that is a \n",
    "# vector of dimension D x 1 which has value 1 for index d-1, and 0 otherwise\n",
    "from scipy.sparse import coo_matrix\n",
    "def convert_to_one_hot(a,max_val=None):\n",
    "    N = a.size\n",
    "    data = np.ones(N,dtype=int)\n",
    "    sparse_out = coo_matrix((data,(np.arange(N),a.ravel())), shape=(N,max_val))\n",
    "    return np.array(sparse_out.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "Run the computational graph with batches of training data.<br> \n",
    "Predict the sequence of characters starting from the character \"h\".<br> \n",
    "\n",
    "Hints:<br>\n",
    "(1) Initial memory is $h_{t=0}$ is 0.<br>\n",
    "(2) Run the computational graph to optimize the perplexity loss, and to predict the the sequence of characters starting from the character \"h\".<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "\n",
      "n= 0 , perplexity value= 23.6872702192\n",
      "starting char= h , predicted sequences= ycxvl\n",
      "7\n",
      "\n",
      "n= 1 , perplexity value= 26.7329419914\n",
      "starting char= h , predicted sequences= elloo\n",
      "7\n",
      "\n",
      "n= 2 , perplexity value= 26.9027156873\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 3 , perplexity value= 26.9634226204\n",
      "starting char= h , predicted sequences= ellnn\n",
      "7\n",
      "\n",
      "n= 4 , perplexity value= 25.9725609885\n",
      "starting char= h , predicted sequences= ell  \n",
      "7\n",
      "\n",
      "n= 5 , perplexity value= 24.2692911776\n",
      "starting char= h , predicted sequences=      \n",
      "7\n",
      "\n",
      "n= 6 , perplexity value= 22.3688664804\n",
      "starting char= h , predicted sequences= e pao\n",
      "7\n",
      "\n",
      "n= 7 , perplexity value= 21.689843211\n",
      "starting char= h , predicted sequences= er gr\n",
      "7\n",
      "\n",
      "n= 8 , perplexity value= 8.19883195178\n",
      "starting char= h , predicted sequences= el  a\n",
      "7\n",
      "\n",
      "n= 9 , perplexity value= 10.2143491041\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 10 , perplexity value= 10.0169961897\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 11 , perplexity value= 11.095749839\n",
      "starting char= h , predicted sequences= elln \n",
      "7\n",
      "\n",
      "n= 12 , perplexity value= 11.2429189353\n",
      "starting char= h , predicted sequences= ella \n",
      "7\n",
      "\n",
      "n= 13 , perplexity value= 10.5273687261\n",
      "starting char= h , predicted sequences= e  a \n",
      "7\n",
      "\n",
      "n= 14 , perplexity value= 9.65883961953\n",
      "starting char= h , predicted sequences= el os\n",
      "7\n",
      "\n",
      "n= 15 , perplexity value= 9.41029128871\n",
      "starting char= h , predicted sequences= el oo\n",
      "7\n",
      "\n",
      "n= 16 , perplexity value= 4.78727548009\n",
      "starting char= h , predicted sequences= el us\n",
      "7\n",
      "\n",
      "n= 17 , perplexity value= 5.56246987926\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 18 , perplexity value= 5.46096966442\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 19 , perplexity value= 6.20036602103\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 20 , perplexity value= 6.33829522537\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 21 , perplexity value= 6.01225274799\n",
      "starting char= h , predicted sequences= e  of\n",
      "7\n",
      "\n",
      "n= 22 , perplexity value= 5.63575878402\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 23 , perplexity value= 5.5578521916\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 24 , perplexity value= 3.15020916745\n",
      "starting char= h , predicted sequences= ellun\n",
      "7\n",
      "\n",
      "n= 25 , perplexity value= 3.7076367112\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 26 , perplexity value= 3.64443733376\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 27 , perplexity value= 4.0764196004\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 28 , perplexity value= 4.13485683599\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 29 , perplexity value= 3.90559118064\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 30 , perplexity value= 3.67428217478\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 31 , perplexity value= 3.7094760448\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 32 , perplexity value= 2.39024591867\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 33 , perplexity value= 2.83207879823\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 34 , perplexity value= 2.78733486637\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 35 , perplexity value= 3.06903194797\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 36 , perplexity value= 3.0035398011\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 37 , perplexity value= 2.83347169229\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 38 , perplexity value= 2.67992859499\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 39 , perplexity value= 2.70209843581\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 40 , perplexity value= 1.89004013163\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 41 , perplexity value= 2.19761275376\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 42 , perplexity value= 2.17253552028\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 43 , perplexity value= 2.38502646182\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 44 , perplexity value= 2.3324132862\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 45 , perplexity value= 2.2347428007\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 46 , perplexity value= 2.13854602038\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 47 , perplexity value= 2.14417857953\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 48 , perplexity value= 1.690387996\n",
      "starting char= h , predicted sequences= ello \n",
      "7\n",
      "\n",
      "n= 49 , perplexity value= 1.87531294395\n",
      "starting char= h , predicted sequences= ello \n"
     ]
    }
   ],
   "source": [
    "# Run CG\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "h0 = np.zeros([batch_size,H], dtype=float)\n",
    "indices = collections.deque()\n",
    "costs = 0.0; epoch_iters = 0\n",
    "for n in range(50):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < 1:\n",
    "        indices.extend(range(epoch_size))\n",
    "        costs = 0.0; epoch_iters = 0\n",
    "    i = indices.popleft() \n",
    "    batch_x = train_data[:,i*T:(i+1)*T]\n",
    "    batch_x = convert_to_one_hot(batch_x,D);\n",
    "    #print(batch_x)\n",
    "    batch_x = np.reshape(batch_x,[batch_size,T,D])\n",
    "    batch_y = train_data[:,i*T+1:(i+1)*T+1]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    idx = char_to_ix['h'];\n",
    "    print(idx)\n",
    "    loss_value,_,Ypredicted = sess.run([loss,train_step,Ypred], feed_dict={xin: batch_x, Ytarget: batch_y, hin: h0, idx_pred: [idx]})   \n",
    "    \n",
    "    # Perplexity\n",
    "    costs += loss_value\n",
    "    epoch_iters += T\n",
    "    perplexity = np.exp(costs/epoch_iters)\n",
    "    \n",
    "    #ix = 0;\n",
    "    if not n%1:\n",
    "        idx_char = Ypredicted\n",
    "        #print(idx_char)\n",
    "        txt = ''.join(ix_to_char[ix] for ix in list(idx_char[:,0]))\n",
    "        print('\\nn=',n,', perplexity value=',perplexity)\n",
    "        print('starting char=',ix_to_char[idx], ', predicted sequences=',txt)\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
